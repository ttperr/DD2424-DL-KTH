{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_properties(i).name)\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 80\n"
     ]
    }
   ],
   "source": [
    "book_fname = 'data/goblet_book.txt'\n",
    "with open(book_fname, 'r') as f:\n",
    "    book_data = f.read()\n",
    "    f.close()\n",
    "\n",
    "book_chars = list(set(book_data))\n",
    "K = len(book_chars)\n",
    "print(f\"Number of unique characters: {K}\")\n",
    "char2ind, ind2char = dict(), dict()\n",
    "for i, c in enumerate(book_chars):\n",
    "    char2ind[c] = i\n",
    "    ind2char[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "\n",
    "    def __init__(self, m=100, seq_length=25, eta=.001, gamma=.9, sig=.01, device=device):\n",
    "        self.m = m\n",
    "        self.seq_length = seq_length\n",
    "        self.eta = eta\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "\n",
    "        self.V = torch.randn(K, m).to(self.device) * sig\n",
    "        self.c = torch.zeros(K, 1).to(self.device)\n",
    "        self.W = torch.randn(m, m).to(self.device) * sig\n",
    "        self.b = torch.zeros(m, 1).to(self.device)\n",
    "        self.U = torch.randn(m, K).to(self.device) * sig\n",
    "\n",
    "        self.V_g_ada = torch.zeros(K, m).to(self.device)\n",
    "        self.c_g_ada = torch.zeros(K, 1).to(self.device)\n",
    "        self.W_g_ada = torch.zeros(m, m).to(self.device)\n",
    "        self.b_g_ada = torch.zeros(m, 1).to(self.device)\n",
    "        self.U_g_ada = torch.zeros(m, K).to(self.device)\n",
    "\n",
    "        self.V_best = self.V.clone()\n",
    "        self.c_best = self.c.clone()\n",
    "        self.W_best = self.W.clone()\n",
    "        self.b_best = self.b.clone()\n",
    "        self.U_best = self.U.clone()\n",
    "\n",
    "        self.smooth_losses = list()\n",
    "\n",
    "        self.grads = {\n",
    "            'V': torch.zeros_like(self.V),\n",
    "            'c': torch.zeros_like(self.c),\n",
    "            'W': torch.zeros_like(self.W),\n",
    "            'b': torch.zeros_like(self.b),\n",
    "            'U': torch.zeros_like(self.U)\n",
    "        }\n",
    "\n",
    "    def synthesize(self, h_prev, x, n, best=False):\n",
    "        Y = torch.zeros((K, n)).to(self.device)\n",
    "        x_t = x\n",
    "        for i in range(n):\n",
    "            h_prev, p = self.forward(h_prev, x_t, best=best)\n",
    "            cp = torch.cumsum(p, dim=0)\n",
    "            r = torch.rand(1)\n",
    "            for j in range(K):\n",
    "                if r < cp[j]:\n",
    "                    break\n",
    "            Y[j, i] = 1\n",
    "            x_t = torch.zeros((K, 1))\n",
    "            x_t[j] = 1\n",
    "        return Y\n",
    "\n",
    "    def forward(self, h_prev, x, best=False):\n",
    "        if not best:\n",
    "            h = torch.tanh(self.W @ h_prev + self.U @ x + self.b)\n",
    "            y = self.V @ h + self.c\n",
    "            p = torch.softmax(y, dim=0)\n",
    "        else:\n",
    "            h = torch.tanh(self.W_best @ h_prev + self.U_best @ x + self.b_best)\n",
    "            y = self.V_best @ h + self.c_best\n",
    "            p = torch.softmax(y, dim=0)\n",
    "        return h, p\n",
    "    \n",
    "    def forward_pass(self, h_0, X, Y, best=False):\n",
    "        h = h_0\n",
    "        H = torch.zeros((self.m, self.seq_length + 1)).to(self.device)\n",
    "        P = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "        H[:, 0] = h.flatten()\n",
    "        loss = 0\n",
    "        for i in range(self.seq_length):\n",
    "            h, p = self.forward(h, X[:, i].reshape(K, 1), best=best)\n",
    "            H[:, i+1] = h.flatten()\n",
    "            P[:, i] = p.flatten()\n",
    "            loss += self.loss(p, Y[:, i].reshape(K, 1))\n",
    "        return H, P, loss\n",
    "\n",
    "    def backward_pass(self, H, P, X, Y):\n",
    "        self.grads = {\n",
    "            'V': torch.zeros_like(self.V),\n",
    "            'c': torch.zeros_like(self.c),\n",
    "            'W': torch.zeros_like(self.W),\n",
    "            'b': torch.zeros_like(self.b),\n",
    "            'U': torch.zeros_like(self.U)\n",
    "        }\n",
    "        dL_dh_next = torch.zeros((self.m, 1)).to(self.device)\n",
    "        h0 = H[:, 0].reshape(self.m, 1)\n",
    "        H = H[:, 1:]\n",
    "        for i in range(self.seq_length-1, -1, -1):\n",
    "            x = X[:, i].reshape(K, 1)\n",
    "            y = Y[:, i].reshape(K, 1)\n",
    "            h = H[:, i].reshape(self.m, 1)\n",
    "            p = P[:, i].reshape(K, 1)\n",
    "            g = (p - y).T\n",
    "            self.grads['V'] += g.T @ h.T\n",
    "            self.grads['c'] += g.T\n",
    "            dL_dh = self.V.T @ g.T + self.W.T @ dL_dh_next\n",
    "            dL_dh_next = dL_dh * (1 - h ** 2)\n",
    "            self.grads['W'] += dL_dh_next @ H[:, i-1].reshape(1, self.m) if i != 0 else dL_dh_next @ h0.T\n",
    "            self.grads['b'] += dL_dh_next\n",
    "            self.grads['U'] += dL_dh_next @ x.T\n",
    "    \n",
    "    def update_params(self, eps=1e-16):\n",
    "        for key in self.grads.keys():\n",
    "            vars(self)[key + '_g_ada'] = self.gamma * vars(self)[key + '_g_ada'] + (1 - self.gamma) * self.grads[key] ** 2\n",
    "            vars(self)[key] -= self.eta * self.grads[key] / torch.sqrt(vars(self)[key + '_g_ada'] + eps)\n",
    "\n",
    "\n",
    "    def loss(self, p, y):\n",
    "        return - torch.sum(y.T @ torch.log(p))\n",
    "\n",
    "    def train(self, book_data, n_epochs=7, eps=1e-16):\n",
    "        n_iter = 0\n",
    "        smooth_loss = 0\n",
    "        best_loss = torch.inf\n",
    "        pbar = trange(n_epochs)\n",
    "        for epoch in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch}/{n_epochs}\")\n",
    "            self.e = 0\n",
    "            h = torch.zeros((self.m, 1)).to(self.device)\n",
    "            while self.e + self.seq_length <= len(book_data):\n",
    "                X_chars = book_data[self.e:self.e+self.seq_length]\n",
    "                Y_chars = book_data[self.e+1:self.e+self.seq_length+1]\n",
    "                X = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "                Y = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "                for i in range(self.seq_length):\n",
    "                    X[char2ind[X_chars[i]], i] = 1\n",
    "                    Y[char2ind[Y_chars[i]], i] = 1\n",
    "\n",
    "                H, P, loss = self.forward_pass(h, X, Y)\n",
    "                self.backward_pass(H, P, X, Y)\n",
    "                self.update_params(eps)\n",
    "\n",
    "                smooth_loss = .999 * smooth_loss + .001 * loss if smooth_loss != 0 else loss\n",
    "                self.smooth_losses.append(smooth_loss)\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    self.V_best = self.V.clone()\n",
    "                    self.c_best = self.c.clone()\n",
    "                    self.W_best = self.W.clone()\n",
    "                    self.b_best = self.b.clone()\n",
    "                    self.U_best = self.U.clone()\n",
    "\n",
    "                h = H[:, -1].reshape(self.m, 1)\n",
    "\n",
    "                n_iter += 1\n",
    "                if n_iter % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"Training - Iteration {n_iter} - Loss {smooth_loss}\")\n",
    "                    \n",
    "                if n_iter % 10000 == 0:\n",
    "                    Y = self.synthesize(h, X[:, 0].reshape(K, 1), 200)\n",
    "                    print()\n",
    "                    print(''.join([ind2char[torch.argmax(Y[:, i]).item()] for i in range(200)]))\n",
    "                    print()\n",
    "\n",
    "                self.e += self.seq_length\n",
    "\n",
    "        print(f\"Training done - Best loss: {best_loss}\")\n",
    "\n",
    "    def check_grads(self, book_data):\n",
    "        for key in self.grads.keys():\n",
    "            vars(self)[key].requires_grad = True\n",
    "\n",
    "        X_chars = book_data[:self.seq_length]\n",
    "        Y_chars = book_data[1:self.seq_length+1]\n",
    "        X = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "        Y = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "        h0 = torch.zeros((self.m, 1)).to(self.device)\n",
    "        for i in range(self.seq_length):\n",
    "            X[char2ind[X_chars[i]], i] = 1\n",
    "            Y[char2ind[Y_chars[i]], i] = 1\n",
    "\n",
    "        H, P, loss = self.forward_pass(h0, X, Y)\n",
    "        self.backward_pass(H, P, X, Y)\n",
    "\n",
    "        for key in self.grads.keys():\n",
    "            vars(self)[key].retain_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        print(\"Checking gradients\")\n",
    "        with torch.no_grad():\n",
    "            for key in self.grads.keys():\n",
    "                diff = torch.norm(self.grads[key] - vars(self)[key].grad)\n",
    "                rel_err = diff / (torch.norm(self.grads[key]) + torch.norm(vars(self)[key].grad) + 1e-16)\n",
    "                print(f\"Relative error on {key}: {rel_err}\")\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.smooth_losses)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Smoothed loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradients\n",
      "Relative error on V: 3.033169448940498e-08\n",
      "Relative error on c: 1.6266680447074577e-08\n",
      "Relative error on W: 4.540372344763455e-08\n",
      "Relative error on b: 3.466666953499953e-08\n",
      "Relative error on U: 3.088153022190454e-08\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "rnn.check_grads(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1526b4da4b2547f48accd02129a33ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Iteration 1000 - Loss 84.24493408203125\n",
      "Training - Iteration 2000 - Loss 70.32706451416016\n",
      "Training - Iteration 3000 - Loss 63.210994720458984\n",
      "Training - Iteration 4000 - Loss 60.10073471069336\n",
      "Training - Iteration 5000 - Loss 58.30186080932617\n",
      "Training - Iteration 6000 - Loss 57.72549057006836\n",
      "Training - Iteration 7000 - Loss 57.41823196411133\n",
      "Training - Iteration 8000 - Loss 55.115230560302734\n",
      "Training - Iteration 9000 - Loss 54.269187927246094\n",
      "Training - Iteration 10000 - Loss 54.042755126953125\n",
      "\n",
      "crimem the roems herarathe fay mumt ou for.. . ood Harmion.  A's 'ver said s notuld dap teey , . \n",
      "Mm. Weaglly kly, ay.\n",
      "\"Pratied ,\"\"Hemrint it sbe lits, y !\"\n",
      "\"Harry yin stoon that snem, and therryony o\n",
      "\n",
      "Training - Iteration 11000 - Loss 54.643150329589844\n",
      "Training - Iteration 12000 - Loss 53.960411071777344\n",
      "Training - Iteration 13000 - Loss 53.06050491333008\n",
      "Training - Iteration 14000 - Loss 52.220428466796875\n",
      "Training - Iteration 15000 - Loss 52.26956558227539\n",
      "Training - Iteration 16000 - Loss 51.098846435546875\n",
      "Training - Iteration 17000 - Loss 50.89724349975586\n",
      "Training - Iteration 18000 - Loss 50.929073333740234\n",
      "Training - Iteration 19000 - Loss 50.61662673950195\n",
      "Training - Iteration 20000 - Loss 49.60470199584961\n",
      "\n",
      "he wast tourtory anabots, Hadd anl, be.  'a syegoinabeatirio. dgat deacarfy.  an iusplene, lowing Hafrye's - and at hed, \" his a rearr, intchittt the forse lengory hang ter!  oI dobken erouget beeme, \n",
      "\n",
      "Training - Iteration 21000 - Loss 49.30015563964844\n",
      "Training - Iteration 22000 - Loss 49.13230895996094\n",
      "Training - Iteration 23000 - Loss 49.218421936035156\n",
      "Training - Iteration 24000 - Loss 49.33391571044922\n",
      "Training - Iteration 25000 - Loss 49.37895202636719\n",
      "Training - Iteration 26000 - Loss 49.29319763183594\n",
      "Training - Iteration 27000 - Loss 48.96461486816406\n",
      "Training - Iteration 28000 - Loss 49.02724838256836\n",
      "Training - Iteration 29000 - Loss 48.39908981323242\n",
      "Training - Iteration 30000 - Loss 48.15650939941406\n",
      "\n",
      "susingby wist of the inper gis. s. ut and war , whtuld ne the sceneers of theer at he'r ceveryloust and dak\" roun, shar, pround, no deed the gwened, thou tew in fleelly of the wryeersow as brends to a\n",
      "\n",
      "Training - Iteration 31000 - Loss 48.6558837890625\n",
      "Training - Iteration 32000 - Loss 47.953643798828125\n",
      "Training - Iteration 33000 - Loss 48.0615119934082\n",
      "Training - Iteration 34000 - Loss 47.079898834228516\n",
      "Training - Iteration 35000 - Loss 46.76829147338867\n",
      "Training - Iteration 36000 - Loss 47.12608337402344\n",
      "Training - Iteration 37000 - Loss 47.42022705078125\n",
      "Training - Iteration 38000 - Loss 47.095645904541016\n",
      "Training - Iteration 39000 - Loss 46.36235427856445\n",
      "Training - Iteration 40000 - Loss 46.50257110595703\n",
      "\n",
      "hit dind into a bl gherwed wind but pomed up, Harry beensnom cuboldissed, thlouse thing asd rownto, he was nome ove which the was to the rebked ropitet we. . It yeal faggorwightred a leep the grached \n",
      "\n",
      "Training - Iteration 41000 - Loss 45.49384689331055\n",
      "Training - Iteration 42000 - Loss 45.02528762817383\n",
      "Training - Iteration 43000 - Loss 45.524635314941406\n",
      "Training - Iteration 44000 - Loss 45.729896545410156\n",
      "Training - Iteration 45000 - Loss 48.12670135498047\n",
      "Training - Iteration 46000 - Loss 47.79874038696289\n",
      "Training - Iteration 47000 - Loss 48.28834915161133\n",
      "Training - Iteration 48000 - Loss 47.36787796020508\n",
      "Training - Iteration 49000 - Loss 47.34245300292969\n",
      "Training - Iteration 50000 - Loss 48.22062683105469\n",
      "\n",
      "goad looking that noubly thearly hesved Higs.\n",
      "\"The very weed enveralbowrons thereas fore.\n",
      "\"Weas a would Harry fror his cemene sharred ha many fliteey like ot a thoy, hel wayveruse bead were of a look \n",
      "\n",
      "Training - Iteration 51000 - Loss 49.550777435302734\n",
      "Training - Iteration 52000 - Loss 47.403873443603516\n",
      "Training - Iteration 53000 - Loss 45.70270538330078\n",
      "Training - Iteration 54000 - Loss 46.48065948486328\n",
      "Training - Iteration 55000 - Loss 49.90210723876953\n",
      "Training - Iteration 56000 - Loss 49.13848114013672\n",
      "Training - Iteration 57000 - Loss 48.15789031982422\n",
      "Training - Iteration 58000 - Loss 46.768470764160156\n",
      "Training - Iteration 59000 - Loss 47.86968994140625\n",
      "Training - Iteration 60000 - Loss 46.462093353271484\n",
      "\n",
      "n mounting tebeilly you,\" said Ronnt,\"\n",
      "chendred in the trouchcuse udented.\n",
      "\"\n",
      "\"irlay saw sta any over their with shat shodened there canted to they hacl is bhis, they reach ewirhed in lepstaniad over i\n",
      "\n",
      "Training - Iteration 61000 - Loss 46.46916961669922\n",
      "Training - Iteration 62000 - Loss 45.91237258911133\n",
      "Training - Iteration 63000 - Loss 46.46127700805664\n",
      "Training - Iteration 64000 - Loss 45.66607666015625\n",
      "Training - Iteration 65000 - Loss 45.43743896484375\n",
      "Training - Iteration 66000 - Loss 44.825096130371094\n",
      "Training - Iteration 67000 - Loss 46.073482513427734\n",
      "Training - Iteration 68000 - Loss 46.08427429199219\n",
      "Training - Iteration 69000 - Loss 46.27873992919922\n",
      "Training - Iteration 70000 - Loss 46.292728424072266\n",
      "\n",
      "able harl.  that he'  yene bade nott's snat ly Dask on his upilion shis seeming at the seapfried countive, and meile looking the gonmpase.  anchours bind naid a not  faisw in yin's flamout looking ove\n",
      "\n",
      "Training - Iteration 71000 - Loss 45.96729278564453\n",
      "Training - Iteration 72000 - Loss 45.97553253173828\n",
      "Training - Iteration 73000 - Loss 45.27718734741211\n",
      "Training - Iteration 74000 - Loss 45.44626235961914\n",
      "Training - Iteration 75000 - Loss 45.27880096435547\n",
      "Training - Iteration 76000 - Loss 45.22478485107422\n",
      "Training - Iteration 77000 - Loss 45.4785270690918\n",
      "Training - Iteration 78000 - Loss 45.00641632080078\n",
      "Training - Iteration 79000 - Loss 43.83051300048828\n",
      "Training - Iteration 80000 - Loss 44.21205139160156\n",
      "\n",
      " ofliehther - hark as that there itchons.\"\n",
      "\"reatly lone thoy,\"  new the soldeing unner ,o. .\n",
      "\". illown and else oit, looken going loss hall fooo makingor a , rase up,\" said  was to the hurtly beenem t\n",
      "\n",
      "Training - Iteration 81000 - Loss 43.713958740234375\n",
      "Training - Iteration 82000 - Loss 44.515987396240234\n",
      "Training - Iteration 83000 - Loss 43.5257568359375\n",
      "Training - Iteration 84000 - Loss 44.69822692871094\n",
      "Training - Iteration 85000 - Loss 43.52604675292969\n",
      "Training - Iteration 86000 - Loss 43.21701431274414\n",
      "Training - Iteration 87000 - Loss 43.786495208740234\n",
      "Training - Iteration 88000 - Loss 43.415409088134766\n",
      "Training - Iteration 89000 - Loss 45.4488410949707\n",
      "Training - Iteration 90000 - Loss 45.28751754760742\n",
      "\n",
      "tane of mipy fir. you, arries, in the wald of find the leaging warous starts he few there awerony his hooment with tiggrace fert Hagrids as undide that you to oumforcition airing for usiod aboch, fupt\n",
      "\n",
      "Training - Iteration 91000 - Loss 46.38264846801758\n",
      "Training - Iteration 92000 - Loss 45.74935531616211\n",
      "Training - Iteration 93000 - Loss 45.539066314697266\n",
      "Training - Iteration 94000 - Loss 46.408538818359375\n",
      "Training - Iteration 95000 - Loss 47.72824478149414\n",
      "Training - Iteration 96000 - Loss 46.66767120361328\n",
      "Training - Iteration 97000 - Loss 44.3443489074707\n",
      "Training - Iteration 98000 - Loss 44.877532958984375\n",
      "Training - Iteration 99000 - Loss 46.06288146972656\n",
      "Training - Iteration 100000 - Loss 47.01350402832031\n",
      "\n",
      "ve, it oo featonse hairsmound whulled .eThe sumbotter tchase whome of reafferlechsly blowen to they all ever as incloo , could srup it  whissor who recudgey, \"looty facen of walter that retchesnor sea\n",
      "\n",
      "Training - Iteration 101000 - Loss 46.95929718017578\n",
      "Training - Iteration 102000 - Loss 45.409393310546875\n",
      "Training - Iteration 103000 - Loss 46.69949722290039\n",
      "Training - Iteration 104000 - Loss 45.23178482055664\n",
      "Training - Iteration 105000 - Loss 44.628395080566406\n",
      "Training - Iteration 106000 - Loss 44.374412536621094\n",
      "Training - Iteration 107000 - Loss 45.304405212402344\n",
      "Training - Iteration 108000 - Loss 44.55525207519531\n",
      "Training - Iteration 109000 - Loss 44.345340728759766\n",
      "Training - Iteration 110000 - Loss 43.69817352294922\n",
      "\n",
      "know Harry's fact with Hart out in a she clupedly,f cetfle suck imcofeep of a mos, soritght, of toor her smate, polll, or m ither think but the a dess, and the came outh, w u'etioushs to was been awar\n",
      "\n",
      "Training - Iteration 111000 - Loss 44.825626373291016\n",
      "Training - Iteration 112000 - Loss 44.73769760131836\n",
      "Training - Iteration 113000 - Loss 45.023807525634766\n",
      "Training - Iteration 114000 - Loss 45.19150924682617\n",
      "Training - Iteration 115000 - Loss 45.30903625488281\n",
      "Training - Iteration 116000 - Loss 44.30826950073242\n",
      "Training - Iteration 117000 - Loss 44.854827880859375\n",
      "Training - Iteration 118000 - Loss 44.74625778198242\n",
      "Training - Iteration 119000 - Loss 43.571048736572266\n",
      "Training - Iteration 120000 - Loss 44.30816650390625\n",
      "\n",
      " at Harryade in rood bould off use pork enrughe they had,\" said Hermaave, and isiwar when they wacky slipting wottorrowing up the and theughted into a shouch remed had bo. .\n",
      "on pustle.  \"beet in smwey\n",
      "\n",
      "Training - Iteration 121000 - Loss 43.886043548583984\n",
      "Training - Iteration 122000 - Loss 44.72123718261719\n",
      "Training - Iteration 123000 - Loss 42.84604263305664\n",
      "Training - Iteration 124000 - Loss 42.558067321777344\n",
      "Training - Iteration 125000 - Loss 42.88775634765625\n",
      "Training - Iteration 126000 - Loss 43.85316467285156\n",
      "Training - Iteration 127000 - Loss 43.335262298583984\n",
      "Training - Iteration 128000 - Loss 43.973419189453125\n",
      "Training - Iteration 129000 - Loss 42.832759857177734\n",
      "Training - Iteration 130000 - Loss 42.99590301513672\n",
      "\n",
      "ten faters plather hur d eysa.  He fassed it the purvesy fass, as pably ance siidly the onviemalt mose, by put llous.  \"day, ramply me to Harry.  shrusleto, with my for the fof pas for myther taking, \n",
      "\n",
      "Training - Iteration 131000 - Loss 42.057193756103516\n",
      "Training - Iteration 132000 - Loss 42.76132583618164\n",
      "Training - Iteration 133000 - Loss 44.61293411254883\n",
      "Training - Iteration 134000 - Loss 44.42005920410156\n",
      "Training - Iteration 135000 - Loss 45.250335693359375\n",
      "Training - Iteration 136000 - Loss 44.892879486083984\n",
      "Training - Iteration 137000 - Loss 44.93631362915039\n",
      "Training - Iteration 138000 - Loss 44.95820236206055\n",
      "Training - Iteration 139000 - Loss 45.75695037841797\n",
      "Training - Iteration 140000 - Loss 47.486698150634766\n",
      "\n",
      "cago I'se a took on went bit acromest illcuuglen shrowh tHarry ctrect her capricarisgleded sealond and wey clowlys lookal . unally with leong and rrplitces and their frot said Mreas the Triyn wut the \n",
      "\n",
      "Training - Iteration 141000 - Loss 44.64752960205078\n",
      "Training - Iteration 142000 - Loss 44.22547912597656\n",
      "Training - Iteration 143000 - Loss 44.76423645019531\n",
      "Training - Iteration 144000 - Loss 47.144920349121094\n",
      "Training - Iteration 145000 - Loss 46.4259147644043\n",
      "Training - Iteration 146000 - Loss 45.112186431884766\n",
      "Training - Iteration 147000 - Loss 46.542484283447266\n",
      "Training - Iteration 148000 - Loss 45.29180908203125\n",
      "Training - Iteration 149000 - Loss 43.69681930541992\n",
      "Training - Iteration 150000 - Loss 43.841800689697266\n",
      "\n",
      "foiciting, him st it, then noth andg each,\" Hs ricked teal a litting to very chapped falld wnatious, atood hive had now .- Im his hands tokly haning some but of him stood, whered than a gowed to chatd\n",
      "\n",
      "Training - Iteration 151000 - Loss 44.54703140258789\n",
      "Training - Iteration 152000 - Loss 44.56769943237305\n",
      "Training - Iteration 153000 - Loss 43.549163818359375\n",
      "Training - Iteration 154000 - Loss 43.17298889160156\n",
      "Training - Iteration 155000 - Loss 43.759788513183594\n",
      "Training - Iteration 156000 - Loss 43.74585723876953\n",
      "Training - Iteration 157000 - Loss 44.09321594238281\n",
      "Training - Iteration 158000 - Loss 44.389129638671875\n",
      "Training - Iteration 159000 - Loss 44.452117919921875\n",
      "Training - Iteration 160000 - Loss 43.943809509277344\n",
      "\n",
      "peet, you had very sottly reen off the ergepther say they no donatve though Harry 'd a veriss had difeillus treor. \"Whato pos thoughtrud, bound, 'm' . . . Hagrlanal us,icat lessly werra, and aling fay\n",
      "\n",
      "Training - Iteration 161000 - Loss 44.05135726928711\n",
      "Training - Iteration 162000 - Loss 43.73038101196289\n",
      "Training - Iteration 163000 - Loss 43.5927848815918\n",
      "Training - Iteration 164000 - Loss 44.32231140136719\n",
      "Training - Iteration 165000 - Loss 43.457489013671875\n",
      "Training - Iteration 166000 - Loss 44.08051681518555\n",
      "Training - Iteration 167000 - Loss 42.99241256713867\n",
      "Training - Iteration 168000 - Loss 42.95086669921875\n",
      "Training - Iteration 169000 - Loss 42.76075744628906\n",
      "Training - Iteration 170000 - Loss 43.71507263183594\n",
      "\n",
      "by.\"\n",
      "for conding ingut the said.  \"He reachich lither dreming to cednle sure any a haking to eg\".  he seeking at ,r goingly of mo died about of the tade ceathing greatly Harry to the esfure, said tore\n",
      "\n",
      "Training - Iteration 171000 - Loss 43.22773361206055\n",
      "Training - Iteration 172000 - Loss 43.00782012939453\n",
      "Training - Iteration 173000 - Loss 42.691959381103516\n",
      "Training - Iteration 174000 - Loss 42.25555419921875\n",
      "Training - Iteration 175000 - Loss 41.4487419128418\n",
      "Training - Iteration 176000 - Loss 42.112796783447266\n",
      "Training - Iteration 177000 - Loss 42.94864273071289\n",
      "Training - Iteration 178000 - Loss 44.85223388671875\n",
      "Training - Iteration 179000 - Loss 44.8249397277832\n",
      "Training - Iteration 180000 - Loss 44.709129333496094\n",
      "\n",
      "ot heard head,\"wa dewhion him to go in it proff hardorwoy, looknce stoppet anotpount's refs seeconsed our cuddle lut was on conllone her and floored ,eat once hispion.  mon'ed wore straughtenily back \n",
      "\n",
      "Training - Iteration 181000 - Loss 44.56696701049805\n",
      "Training - Iteration 182000 - Loss 44.47136306762695\n",
      "Training - Iteration 183000 - Loss 45.67081069946289\n",
      "Training - Iteration 184000 - Loss 47.18215560913086\n",
      "Training - Iteration 185000 - Loss 44.677520751953125\n",
      "Training - Iteration 186000 - Loss 43.68653106689453\n",
      "Training - Iteration 187000 - Loss 43.942283630371094\n",
      "Training - Iteration 188000 - Loss 47.87118148803711\n",
      "Training - Iteration 189000 - Loss 46.789363861083984\n",
      "Training - Iteration 190000 - Loss 45.44694900512695\n",
      "\n",
      "n toaicy twoescy rol - chan wurncem gumple at earidy every.\n",
      "\"deaking ha member, could hurtiner to sayed if its ble impiniand asoubot.  a my laught and fon't mood Malting mapking blhear thit aled into \n",
      "\n",
      "Training - Iteration 191000 - Loss 44.179725646972656\n",
      "Training - Iteration 192000 - Loss 45.18760299682617\n",
      "Training - Iteration 193000 - Loss 43.8250617980957\n",
      "Training - Iteration 194000 - Loss 43.800140380859375\n",
      "Training - Iteration 195000 - Loss 43.33124542236328\n",
      "Training - Iteration 196000 - Loss 44.432579040527344\n",
      "Training - Iteration 197000 - Loss 43.525325775146484\n",
      "Training - Iteration 198000 - Loss 42.990966796875\n",
      "Training - Iteration 199000 - Loss 42.59982681274414\n",
      "Training - Iteration 200000 - Loss 43.72748947143555\n",
      "\n",
      " loncles frowly after , a boodsber' have sorthing to wires fours wond, scooding arue diddes moreing at not, said howcer, rood noehat downing, sco gem their wants a h whaiking's beer panghed want as he\n",
      "\n",
      "Training - Iteration 201000 - Loss 44.140132904052734\n",
      "Training - Iteration 202000 - Loss 44.072994232177734\n",
      "Training - Iteration 203000 - Loss 44.36183547973633\n",
      "Training - Iteration 204000 - Loss 43.68537521362305\n",
      "Training - Iteration 205000 - Loss 43.94576644897461\n",
      "Training - Iteration 206000 - Loss 43.135684967041016\n",
      "Training - Iteration 207000 - Loss 43.468875885009766\n",
      "Training - Iteration 208000 - Loss 43.53101348876953\n",
      "Training - Iteration 209000 - Loss 43.250186920166016\n",
      "Training - Iteration 210000 - Loss 43.84014892578125\n",
      "\n",
      "p , Serging listleel him,\" said in frehcls o to found eas if he feight.  and, they to begat them at elp wly. ine's \"pedring ubley're, were wove guw harsd.\"\n",
      "\"batched Hagrid walh's her, whichled., \"the \n",
      "\n",
      "Training - Iteration 211000 - Loss 42.726470947265625\n",
      "Training - Iteration 212000 - Loss 42.12923812866211\n",
      "Training - Iteration 213000 - Loss 42.57696533203125\n",
      "Training - Iteration 214000 - Loss 42.0317497253418\n",
      "Training - Iteration 215000 - Loss 42.666160583496094\n",
      "Training - Iteration 216000 - Loss 41.9716911315918\n",
      "Training - Iteration 217000 - Loss 43.05849075317383\n",
      "Training - Iteration 218000 - Loss 42.00108337402344\n",
      "Training - Iteration 219000 - Loss 41.6632080078125\n",
      "Training - Iteration 220000 - Loss 41.972835540771484\n",
      "\n",
      "swil es the was returnest of the polemouse reclievstring oim you son't both the life and at to you tham if you,\" behirtesus of cainidueded foen.\"\n",
      "\"lest all to feill dil, whise ear wirly in Dcarmed now\n",
      "\n",
      "Training - Iteration 221000 - Loss 42.20088195800781\n",
      "Training - Iteration 222000 - Loss 44.399192810058594\n",
      "Training - Iteration 223000 - Loss 43.51754379272461\n",
      "Training - Iteration 224000 - Loss 44.5860710144043\n",
      "Training - Iteration 225000 - Loss 44.00255584716797\n",
      "Training - Iteration 226000 - Loss 44.39130783081055\n",
      "Training - Iteration 227000 - Loss 45.126136779785156\n",
      "Training - Iteration 228000 - Loss 46.602901458740234\n",
      "Training - Iteration 229000 - Loss 45.10665512084961\n",
      "Training - Iteration 230000 - Loss 42.598289489746094\n",
      "\n",
      "rned show unter it, back in raghasking phisher' atched,\" nswartly tober?\"\n",
      "\"\n",
      "\"ne propping to your notaned a brough when their choen was taking robe touch. \n",
      "\"beyove fares with rlisteny.. , his wand, her\n",
      "\n",
      "Training - Iteration 231000 - Loss 43.747779846191406\n",
      "Training - Iteration 232000 - Loss 44.60954284667969\n",
      "Training - Iteration 233000 - Loss 45.61910629272461\n",
      "Training - Iteration 234000 - Loss 45.87080764770508\n",
      "Training - Iteration 235000 - Loss 44.1312370300293\n",
      "Training - Iteration 236000 - Loss 45.518985748291016\n",
      "Training - Iteration 237000 - Loss 43.56130599975586\n",
      "Training - Iteration 238000 - Loss 43.478431701660156\n",
      "Training - Iteration 239000 - Loss 43.003597259521484\n",
      "Training - Iteration 240000 - Loss 43.85807800292969\n",
      "\n",
      " them,\" said Harry up and enter, her chights of woars to her thinky wourd that  dished it enters..  Harry was poin thot was arou, and melver and eyes of the these stove.\n",
      "\"onsulliusus. yoom aboe like t\n",
      "\n",
      "Training - Iteration 241000 - Loss 43.01218795776367\n",
      "Training - Iteration 242000 - Loss 42.79092788696289\n",
      "Training - Iteration 243000 - Loss 42.40727233886719\n",
      "Training - Iteration 244000 - Loss 43.76261901855469\n",
      "Training - Iteration 245000 - Loss 43.33327102661133\n",
      "Training - Iteration 246000 - Loss 43.61489486694336\n",
      "Training - Iteration 247000 - Loss 43.71377182006836\n",
      "Training - Iteration 248000 - Loss 44.38178253173828\n",
      "Training - Iteration 249000 - Loss 43.40251922607422\n",
      "Training - Iteration 250000 - Loss 43.63435745239258\n",
      "\n",
      ", and serivion oat man and the unated by then  oor cloating more iro\" some on its'y walked, lighter, hearr toweed he sear, and their olled dis iwe, and thinking with himpare ald front dessitephessed, \n",
      "\n",
      "Training - Iteration 251000 - Loss 43.61277389526367\n",
      "Training - Iteration 252000 - Loss 42.57744598388672\n",
      "Training - Iteration 253000 - Loss 43.293426513671875\n",
      "Training - Iteration 254000 - Loss 42.75254821777344\n",
      "Training - Iteration 255000 - Loss 43.38541793823242\n",
      "Training - Iteration 256000 - Loss 41.585758209228516\n",
      "Training - Iteration 257000 - Loss 41.57838439941406\n",
      "Training - Iteration 258000 - Loss 41.510555267333984\n",
      "Training - Iteration 259000 - Loss 42.64791488647461\n",
      "Training - Iteration 260000 - Loss 42.15393829345703\n",
      "\n",
      "ten as fouth, Harry'd feighed it his a horkst'sming toward his as what the sheilins, alIn  hoiched a s olook dritioned dishroktor the hI grounding not shope and fullased that \"k I, novely pold her. . \n",
      "\n",
      "Training - Iteration 261000 - Loss 42.89094543457031\n",
      "Training - Iteration 262000 - Loss 41.56621170043945\n",
      "Training - Iteration 263000 - Loss 41.76090621948242\n",
      "Training - Iteration 264000 - Loss 41.114341735839844\n",
      "Training - Iteration 265000 - Loss 41.53921127319336\n",
      "Training - Iteration 266000 - Loss 44.20172882080078\n",
      "Training - Iteration 267000 - Loss 43.48893356323242\n",
      "Training - Iteration 268000 - Loss 44.067115783691406\n",
      "Training - Iteration 269000 - Loss 43.68033981323242\n",
      "Training - Iteration 270000 - Loss 43.76073455810547\n",
      "\n",
      "surbled and the dot.  s impers., Mully and they''r a for the time to than a libing, and will are the pleasartly srebdor, gished esna buth, and nevery's groat fllown thry I cance peher orskund than a l\n",
      "\n",
      "Training - Iteration 271000 - Loss 44.20650863647461\n",
      "Training - Iteration 272000 - Loss 45.10196304321289\n",
      "Training - Iteration 273000 - Loss 45.96815872192383\n",
      "Training - Iteration 274000 - Loss 43.29167556762695\n",
      "Training - Iteration 275000 - Loss 43.55460739135742\n",
      "Training - Iteration 276000 - Loss 43.886444091796875\n",
      "Training - Iteration 277000 - Loss 46.03358840942383\n",
      "Training - Iteration 278000 - Loss 45.99613952636719\n",
      "Training - Iteration 279000 - Loss 44.06913375854492\n",
      "Training - Iteration 280000 - Loss 45.82781982421875\n",
      "\n",
      "awing foun of the rellasparaily thoir a room but it about tond tteked alle hands you not his e.\n",
      "\"dayse seered about the knoppipuonts as Haddild very and the respuaredson tellly.  secalling neor drawli\n",
      "\n",
      "Training - Iteration 281000 - Loss 44.309234619140625\n",
      "Training - Iteration 282000 - Loss 42.857933044433594\n",
      "Training - Iteration 283000 - Loss 42.68815994262695\n",
      "Training - Iteration 284000 - Loss 43.68996810913086\n",
      "Training - Iteration 285000 - Loss 43.335758209228516\n",
      "Training - Iteration 286000 - Loss 42.35205078125\n",
      "Training - Iteration 287000 - Loss 42.12040710449219\n",
      "Training - Iteration 288000 - Loss 43.14215850830078\n",
      "Training - Iteration 289000 - Loss 43.286399841308594\n",
      "Training - Iteration 290000 - Loss 43.150943756103516\n",
      "\n",
      "down had see.  need sorge as, we inser and belring, seadd with sirentrilard.  a hops gainffully to arghable blan, and near le.  Hes for the than to to a so into the back.  \"hobded, every said Harry in\n",
      "\n",
      "Training - Iteration 291000 - Loss 43.77334213256836\n",
      "Training - Iteration 292000 - Loss 43.14603805541992\n",
      "Training - Iteration 293000 - Loss 43.2891845703125\n",
      "Training - Iteration 294000 - Loss 43.34926986694336\n",
      "Training - Iteration 295000 - Loss 43.05849075317383\n",
      "Training - Iteration 296000 - Loss 42.69001770019531\n",
      "Training - Iteration 297000 - Loss 43.40470504760742\n",
      "Training - Iteration 298000 - Loss 42.5189208984375\n",
      "Training - Iteration 299000 - Loss 43.36720275878906\n",
      "Training - Iteration 300000 - Loss 42.06747817993164\n",
      "\n",
      " Harry ensaing abous aboud,  horning at him that insted reatonsaring,\"\n",
      "\"me sa ttreed , nogmast hask.\n",
      "\"He bal, three enterfier hill and sitting compely.\n",
      "\"ot mounting of a phoodgey, and Dumbledores sone\n",
      "\n",
      "Training - Iteration 301000 - Loss 41.831748962402344\n",
      "Training - Iteration 302000 - Loss 42.03094482421875\n",
      "Training - Iteration 303000 - Loss 42.835426330566406\n",
      "Training - Iteration 304000 - Loss 42.333343505859375\n",
      "Training - Iteration 305000 - Loss 42.59842300415039\n",
      "Training - Iteration 306000 - Loss 41.7004280090332\n",
      "Training - Iteration 307000 - Loss 41.50950622558594\n",
      "Training - Iteration 308000 - Loss 40.51664733886719\n",
      "Training - Iteration 309000 - Loss 41.24656677246094\n",
      "Training - Iteration 310000 - Loss 42.40571212768555\n",
      "\n",
      "ven donsly, give year atherpared the .re.\n",
      "\"Harrys mald turnin's and they wering , our held him, and than you's bissions bit me tood it was to rimfwing is thi looking sk\n",
      "becadmend said he, \"We,\" out fe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "rnn.train(book_data, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arry, lon't cittred thoughtereath her shared the tangutch here,  oe's gone in they're was suently dasg becosven howe-f Muggory somenoring. \" ill of they didn't been lost us emblant tond going to harry hoy preby, nowd. \"em's powk whetrepred of would they' he'me as tis nith?r flats of it washing into his lons eyen a hafter, . . . \"we srain.\n",
      "\"choilt he repoing dose he toke \"\n",
      "\"uf was scorted and blinction.  The supps ofraid for,\" said reat of Mr. Muof ce, it's fating track\n",
      "\"I have rearlling him. . .\" oate, at the siHarry, liken flows and he the pit of them.  \"'s goits were for it fore when they add never they' repoars them, they'r my, behindout they donen,\" beard knogart as folding untors.  \"now he hundinly teblo cooding on off don't his thot had nowd whot then youdd themn whill use like to than the ploters him Mr.\n",
      "\"Werone back, been palf.  fcate whing it did in the sound.shere lest'linneched an coaded. , them olle rut they find off her,\" sied tonsurid them sheating from onech, as therofee\n"
     ]
    }
   ],
   "source": [
    "starting_char = 'H'\n",
    "X = torch.zeros((K, 1)).to(device)\n",
    "X[char2ind[starting_char], 0] = 1\n",
    "h = torch.zeros((rnn.m, 1)).to(device)\n",
    "Y = rnn.synthesize(h, X, 1000, best=True)\n",
    "print(starting_char + ''.join([ind2char[torch.argmax(Y[:, i]).item()] for i in range(1000)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
