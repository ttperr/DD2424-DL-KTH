{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_properties(i).name)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 80\n"
     ]
    }
   ],
   "source": [
    "book_fname = 'data/goblet_book.txt'\n",
    "with open(book_fname, 'r') as f:\n",
    "    book_data = f.read()\n",
    "    f.close()\n",
    "\n",
    "book_chars = list(set(book_data))\n",
    "K = len(book_chars)\n",
    "print(f\"Number of unique characters: {K}\")\n",
    "char2ind, ind2char = dict(), dict()\n",
    "for i, c in enumerate(book_chars):\n",
    "    char2ind[c] = i\n",
    "    ind2char[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "\n",
    "    def __init__(self, m=100, seq_length=25, eta=.001, gamma=.9, sig=.01, device=device):\n",
    "        self.m = m\n",
    "        self.seq_length = seq_length\n",
    "        self.eta = eta\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "\n",
    "        self.V = torch.randn(K, m).to(self.device) * sig\n",
    "        self.c = torch.zeros(K, 1).to(self.device)\n",
    "        self.W = torch.randn(m, m).to(self.device) * sig\n",
    "        self.b = torch.zeros(m, 1).to(self.device)\n",
    "        self.U = torch.randn(m, K).to(self.device) * sig\n",
    "\n",
    "        self.V_g_ada = torch.zeros(K, m).to(self.device)\n",
    "        self.c_g_ada = torch.zeros(K, 1).to(self.device)\n",
    "        self.W_g_ada = torch.zeros(m, m).to(self.device)\n",
    "        self.b_g_ada = torch.zeros(m, 1).to(self.device)\n",
    "        self.U_g_ada = torch.zeros(m, K).to(self.device)\n",
    "\n",
    "        self.V_best = self.V.clone()\n",
    "        self.c_best = self.c.clone()\n",
    "        self.W_best = self.W.clone()\n",
    "        self.b_best = self.b.clone()\n",
    "        self.U_best = self.U.clone()\n",
    "\n",
    "        self.smooth_losses = list()\n",
    "\n",
    "        self.grads = {\n",
    "            'V': torch.zeros_like(self.V),\n",
    "            'c': torch.zeros_like(self.c),\n",
    "            'W': torch.zeros_like(self.W),\n",
    "            'b': torch.zeros_like(self.b),\n",
    "            'U': torch.zeros_like(self.U)\n",
    "        }\n",
    "\n",
    "    def synthesize(self, h_prev, x, n, best=False):\n",
    "        Y = torch.zeros((K, n)).to(self.device)\n",
    "        x_t = x\n",
    "        for i in range(n):\n",
    "            h_prev, p = self.forward(h_prev, x_t, best=best)\n",
    "            cp = torch.cumsum(p, dim=0)\n",
    "            r = torch.rand(1)\n",
    "            for j in range(K):\n",
    "                if r < cp[j]:\n",
    "                    break\n",
    "            Y[j, i] = 1\n",
    "            x_t = torch.zeros((K, 1))\n",
    "            x_t[j] = 1\n",
    "        return Y\n",
    "\n",
    "    def forward(self, h_prev, x, best=False):\n",
    "        if not best:\n",
    "            h = torch.tanh(self.W @ h_prev + self.U @ x + self.b)\n",
    "            y = self.V @ h + self.c\n",
    "            p = torch.softmax(y, dim=0)\n",
    "        else:\n",
    "            h = torch.tanh(self.W_best @ h_prev + self.U_best @ x + self.b_best)\n",
    "            y = self.V_best @ h + self.c_best\n",
    "            p = torch.softmax(y, dim=0)\n",
    "        return h, p\n",
    "    \n",
    "    def forward_pass(self, h_0, X, Y, best=False):\n",
    "        h = h_0\n",
    "        H = torch.zeros((self.m, self.seq_length + 1)).to(self.device)\n",
    "        P = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "        H[:, 0] = h.flatten()\n",
    "        loss = 0\n",
    "        for i in range(self.seq_length):\n",
    "            h, p = self.forward(h, X[:, i].reshape(K, 1), best=best)\n",
    "            H[:, i+1] = h.flatten()\n",
    "            P[:, i] = p.flatten()\n",
    "            loss += self.loss(p, Y[:, i].reshape(K, 1))\n",
    "        return H, P, loss\n",
    "\n",
    "    def backward_pass(self, H, P, X, Y):\n",
    "        self.grads = {\n",
    "            'V': torch.zeros_like(self.V),\n",
    "            'c': torch.zeros_like(self.c),\n",
    "            'W': torch.zeros_like(self.W),\n",
    "            'b': torch.zeros_like(self.b),\n",
    "            'U': torch.zeros_like(self.U)\n",
    "        }\n",
    "        dL_dh_next = torch.zeros((self.m, 1)).to(self.device)\n",
    "        h0 = H[:, 0].reshape(self.m, 1)\n",
    "        H = H[:, 1:]\n",
    "        for i in range(self.seq_length-1, -1, -1):\n",
    "            x = X[:, i].reshape(K, 1)\n",
    "            y = Y[:, i].reshape(K, 1)\n",
    "            h = H[:, i].reshape(self.m, 1)\n",
    "            p = P[:, i].reshape(K, 1)\n",
    "            g = (p - y).T\n",
    "            self.grads['V'] += g.T @ h.T\n",
    "            self.grads['c'] += g.T\n",
    "            dL_dh = self.V.T @ g.T + self.W.T @ dL_dh_next\n",
    "            dL_dh_next = dL_dh * (1 - h ** 2)\n",
    "            self.grads['W'] += dL_dh_next @ H[:, i-1].reshape(1, self.m) if i != 0 else dL_dh_next @ h0.T\n",
    "            self.grads['b'] += dL_dh_next\n",
    "            self.grads['U'] += dL_dh_next @ x.T\n",
    "    \n",
    "    def update_params(self, eps=1e-16):\n",
    "        for key in self.grads.keys():\n",
    "            self.grads[key] = torch.clamp(self.grads[key], -5, 5)\n",
    "            vars(self)[key + '_g_ada'] = self.gamma * vars(self)[key + '_g_ada'] + (1 - self.gamma) * self.grads[key] ** 2\n",
    "            vars(self)[key] -= self.eta * self.grads[key] / torch.sqrt(vars(self)[key + '_g_ada'] + eps)\n",
    "\n",
    "\n",
    "    def loss(self, p, y):\n",
    "        return - torch.sum(y.T @ torch.log(p))\n",
    "\n",
    "    def train(self, book_data, n_epochs=7, eps=1e-16):\n",
    "        n_iter = 0\n",
    "        smooth_loss = 0\n",
    "        best_loss = torch.inf\n",
    "        pbar = trange(n_epochs)\n",
    "        for epoch in pbar:\n",
    "            pbar.set_description(f\"Epoch {epoch}/{n_epochs}\")\n",
    "            self.e = 0\n",
    "            h = torch.zeros((self.m, 1)).to(self.device)\n",
    "            while self.e + self.seq_length <= len(book_data):\n",
    "                X_chars = book_data[self.e:self.e+self.seq_length]\n",
    "                Y_chars = book_data[self.e+1:self.e+self.seq_length+1]\n",
    "                X = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "                Y = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "                for i in range(self.seq_length):\n",
    "                    X[char2ind[X_chars[i]], i] = 1\n",
    "                    Y[char2ind[Y_chars[i]], i] = 1\n",
    "\n",
    "                H, P, loss = self.forward_pass(h, X, Y)\n",
    "                self.backward_pass(H, P, X, Y)\n",
    "                self.update_params(eps)\n",
    "\n",
    "                smooth_loss = .999 * smooth_loss + .001 * loss if smooth_loss != 0 else loss\n",
    "                self.smooth_losses.append(smooth_loss)\n",
    "\n",
    "                if smooth_loss < best_loss:\n",
    "                    best_loss = smooth_loss\n",
    "                    self.V_best = self.V.clone()\n",
    "                    self.c_best = self.c.clone()\n",
    "                    self.W_best = self.W.clone()\n",
    "                    self.b_best = self.b.clone()\n",
    "                    self.U_best = self.U.clone()\n",
    "\n",
    "                h = H[:, -1].reshape(self.m, 1)\n",
    "\n",
    "                n_iter += 1\n",
    "                if n_iter % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"Training - Iteration {n_iter} - Loss {smooth_loss}\")\n",
    "                    \n",
    "                if n_iter % 10000 == 0:\n",
    "                    Y = self.synthesize(h, X[:, 0].reshape(K, 1), 200)\n",
    "                    print()\n",
    "                    print(''.join([ind2char[torch.argmax(Y[:, i]).item()] for i in range(200)]))\n",
    "                    print()\n",
    "\n",
    "                self.e += self.seq_length\n",
    "\n",
    "        print(f\"Training done - Best loss: {best_loss}\")\n",
    "\n",
    "    def check_grads(self, book_data):\n",
    "        for key in self.grads.keys():\n",
    "            vars(self)[key].requires_grad = True\n",
    "\n",
    "        X_chars = book_data[:self.seq_length]\n",
    "        Y_chars = book_data[1:self.seq_length+1]\n",
    "        X = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "        Y = torch.zeros((K, self.seq_length)).to(self.device)\n",
    "        h0 = torch.zeros((self.m, 1)).to(self.device)\n",
    "        for i in range(self.seq_length):\n",
    "            X[char2ind[X_chars[i]], i] = 1\n",
    "            Y[char2ind[Y_chars[i]], i] = 1\n",
    "\n",
    "        H, P, loss = self.forward_pass(h0, X, Y)\n",
    "        self.backward_pass(H, P, X, Y)\n",
    "\n",
    "        for key in self.grads.keys():\n",
    "            vars(self)[key].retain_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        print(\"Checking gradients\")\n",
    "        with torch.no_grad():\n",
    "            for key in self.grads.keys():\n",
    "                diff = torch.norm(self.grads[key] - vars(self)[key].grad)\n",
    "                rel_err = diff / (torch.norm(self.grads[key]) + torch.norm(vars(self)[key].grad) + 1e-16)\n",
    "                print(f\"Relative error on {key}: {rel_err}\")\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.smooth_losses)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Smoothed loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradients\n",
      "Relative error on V: 2.41572895021136e-08\n",
      "Relative error on c: 2.6179758805255915e-08\n",
      "Relative error on W: 4.325439562080646e-08\n",
      "Relative error on b: 3.737445553042562e-08\n",
      "Relative error on U: 2.973572144071568e-08\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "rnn.check_grads(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a2c05ad8ec45fb802a94f766f3e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Iteration 1000 - Loss 84.29646301269531\n",
      "Training - Iteration 2000 - Loss 70.2965316772461\n",
      "Training - Iteration 3000 - Loss 63.12345886230469\n",
      "Training - Iteration 4000 - Loss 60.032535552978516\n",
      "Training - Iteration 5000 - Loss 58.26274108886719\n",
      "Training - Iteration 6000 - Loss 57.67570495605469\n",
      "Training - Iteration 7000 - Loss 57.29396438598633\n",
      "Training - Iteration 8000 - Loss 54.99694061279297\n",
      "Training - Iteration 9000 - Loss 54.12350845336914\n",
      "Training - Iteration 10000 - Loss 53.94949722290039\n",
      "\n",
      "thus wave he toound Could in tra yo?\" thinge yo's got Hempling of oun i!\"\n",
      "sas ant got.M \"bHarre las toedargentther hey ser ther koy Hormy peartinn aigll's sheromers, sand the tinding shat aid coums,\" \n",
      "\n",
      "Training - Iteration 11000 - Loss 54.53718566894531\n",
      "Training - Iteration 12000 - Loss 53.878273010253906\n",
      "Training - Iteration 13000 - Loss 53.06559371948242\n",
      "Training - Iteration 14000 - Loss 52.29709243774414\n",
      "Training - Iteration 15000 - Loss 52.3012580871582\n",
      "Training - Iteration 16000 - Loss 51.187950134277344\n",
      "Training - Iteration 17000 - Loss 51.11173629760742\n",
      "Training - Iteration 18000 - Loss 51.25349807739258\n",
      "Training - Iteration 19000 - Loss 50.8899040222168\n",
      "Training - Iteration 20000 - Loss 49.88121795654297\n",
      "\n",
      "\n",
      "ryetherdind aly cham seagoted ot thit wir\"\n",
      "\" ham hHarriy counond seants aling uppot houling anoer -ho downt're dill wat grit black shew se speess curien soldote.  Hagrikis.  \"He witares sakbyens war \n",
      "\n",
      "Training - Iteration 21000 - Loss 49.5594596862793\n",
      "Training - Iteration 22000 - Loss 49.302574157714844\n",
      "Training - Iteration 23000 - Loss 49.38228225708008\n",
      "Training - Iteration 24000 - Loss 49.47188186645508\n",
      "Training - Iteration 25000 - Loss 49.445865631103516\n",
      "Training - Iteration 26000 - Loss 49.30613327026367\n",
      "Training - Iteration 27000 - Loss 49.02029037475586\n",
      "Training - Iteration 28000 - Loss 48.87721252441406\n",
      "Training - Iteration 29000 - Loss 48.282405853271484\n",
      "Training - Iteration 30000 - Loss 48.07329177856445\n",
      "\n",
      "weer wasned the flen the ained a\n",
      "\"th the yorlake lestaintly pfistout dragrle as nef car s, pe'spaith tatery.  nteby hind\n",
      "able ow got tark to the ae bock treacla giant mors be bleckes of mare the uroul\n",
      "\n",
      "Training - Iteration 31000 - Loss 48.539371490478516\n",
      "Training - Iteration 32000 - Loss 47.809993743896484\n",
      "Training - Iteration 33000 - Loss 47.97334289550781\n",
      "Training - Iteration 34000 - Loss 47.08810043334961\n",
      "Training - Iteration 35000 - Loss 46.743473052978516\n",
      "Training - Iteration 36000 - Loss 46.97207260131836\n",
      "Training - Iteration 37000 - Loss 47.339447021484375\n",
      "Training - Iteration 38000 - Loss 46.94629669189453\n",
      "Training - Iteration 39000 - Loss 46.29318618774414\n",
      "Training - Iteration 40000 - Loss 46.391456604003906\n",
      "\n",
      "hen even ele commfone is whered feithllion, lost  netwhis wave this  smeah waters thered was worded then sif no loughthemie'd mringed you that was gelins fochelietly a, a wolly was sued whete ffoigh r\n",
      "\n",
      "Training - Iteration 41000 - Loss 45.46372985839844\n",
      "Training - Iteration 42000 - Loss 44.92684555053711\n",
      "Training - Iteration 43000 - Loss 45.48504638671875\n",
      "Training - Iteration 44000 - Loss 45.596927642822266\n",
      "Training - Iteration 45000 - Loss 47.99869918823242\n",
      "Training - Iteration 46000 - Loss 47.68975067138672\n",
      "Training - Iteration 47000 - Loss 48.18779373168945\n",
      "Training - Iteration 48000 - Loss 47.42698669433594\n",
      "Training - Iteration 49000 - Loss 47.38523864746094\n",
      "Training - Iteration 50000 - Loss 48.236244201660156\n",
      "\n",
      "his slentereden in weetlass fursice the word retove you and aHmeble wusling.  boymsondefryouins righind.\"\n",
      "rey in upby facamard itlly paiging and thes and he caftich.\n",
      "\"Theymednot haTh hadrsmon.  tay, h\n",
      "\n",
      "Training - Iteration 51000 - Loss 49.8311767578125\n",
      "Training - Iteration 52000 - Loss 47.55909729003906\n",
      "Training - Iteration 53000 - Loss 45.84751510620117\n",
      "Training - Iteration 54000 - Loss 46.4981689453125\n",
      "Training - Iteration 55000 - Loss 49.732357025146484\n",
      "Training - Iteration 56000 - Loss 49.05770492553711\n",
      "Training - Iteration 57000 - Loss 48.01660919189453\n",
      "Training - Iteration 58000 - Loss 46.68115997314453\n",
      "Training - Iteration 59000 - Loss 47.8869743347168\n",
      "Training - Iteration 60000 - Loss 46.309410095214844\n",
      "\n",
      "usw of liwith of the grauccanifurcing the gvan, sore as them.\n",
      "oked his for themion. le ghe though, ancerrawc, geannkin, ue leaving back ywangs in anous an ent looking. unwitch.  The encp rt a gganks t\n",
      "\n",
      "Training - Iteration 61000 - Loss 46.406829833984375\n",
      "Training - Iteration 62000 - Loss 45.969383239746094\n",
      "Training - Iteration 63000 - Loss 46.52212905883789\n",
      "Training - Iteration 64000 - Loss 45.67262649536133\n",
      "Training - Iteration 65000 - Loss 45.36376953125\n",
      "Training - Iteration 66000 - Loss 44.747982025146484\n",
      "Training - Iteration 67000 - Loss 46.06841278076172\n",
      "Training - Iteration 68000 - Loss 46.19642639160156\n",
      "Training - Iteration 69000 - Loss 46.344669342041016\n",
      "Training - Iteration 70000 - Loss 46.31638717651367\n",
      "\n",
      "ill Harry and out this antrusan mebre cait eegrile.\n",
      "\"It's pand, dikid a .\"\n",
      "\"ris down the onely frobeell they moully, onnistry.  marks at the to rrouly an boinge plonet seir  leaher at boing of histing\n",
      "\n",
      "Training - Iteration 71000 - Loss 46.14860916137695\n",
      "Training - Iteration 72000 - Loss 46.05961608886719\n",
      "Training - Iteration 73000 - Loss 45.516151428222656\n",
      "Training - Iteration 74000 - Loss 45.615135192871094\n",
      "Training - Iteration 75000 - Loss 45.38707733154297\n",
      "Training - Iteration 76000 - Loss 45.326751708984375\n",
      "Training - Iteration 77000 - Loss 45.39716720581055\n",
      "Training - Iteration 78000 - Loss 44.96254348754883\n",
      "Training - Iteration 79000 - Loss 43.86873245239258\n",
      "Training - Iteration 80000 - Loss 44.3581657409668\n",
      "\n",
      " him . . . Harrys were in to to might was said app sleessise.\n",
      "\n",
      "\"ormaid at suct silter of his inly.  refore walked do,  nufbed all at the.\n",
      "\"loaking of fitch is back cunes \"rea of the ttouled, growled a\n",
      "\n",
      "Training - Iteration 81000 - Loss 43.80935287475586\n",
      "Training - Iteration 82000 - Loss 44.536865234375\n",
      "Training - Iteration 83000 - Loss 43.71809768676758\n",
      "Training - Iteration 84000 - Loss 44.65205764770508\n",
      "Training - Iteration 85000 - Loss 43.54640197753906\n",
      "Training - Iteration 86000 - Loss 43.15813446044922\n",
      "Training - Iteration 87000 - Loss 43.851844787597656\n",
      "Training - Iteration 88000 - Loss 43.46994400024414\n",
      "Training - Iteration 89000 - Loss 45.498504638671875\n",
      "Training - Iteration 90000 - Loss 45.28731918334961\n",
      "\n",
      "saling tamiry looked hi aleked at spoffrow's keep its Harry.  ... but to heard a cande he eauld his eysy him gas his spigcles, and  I was again, he silt abbuching a wanded to, but his scar, and theors\n",
      "\n",
      "Training - Iteration 91000 - Loss 46.21163558959961\n",
      "Training - Iteration 92000 - Loss 45.8463134765625\n",
      "Training - Iteration 93000 - Loss 45.62409591674805\n",
      "Training - Iteration 94000 - Loss 46.6752815246582\n",
      "Training - Iteration 95000 - Loss 47.71186065673828\n",
      "Training - Iteration 96000 - Loss 46.89464569091797\n",
      "Training - Iteration 97000 - Loss 44.58121109008789\n",
      "Training - Iteration 98000 - Loss 45.05939483642578\n",
      "Training - Iteration 99000 - Loss 46.21723175048828\n",
      "Training - Iteration 100000 - Loss 47.12461471557617\n",
      "\n",
      "riles.\"\n",
      "\"tenth refarent aluch, about to down from wpen shough tthis your not you doou, you ligr a platch set we causly ihunder down timben deosnst eehied with be yeally.  \"f yaf speed,\" said, ynat he \n",
      "\n",
      "Training - Iteration 101000 - Loss 46.98173904418945\n",
      "Training - Iteration 102000 - Loss 45.53349685668945\n",
      "Training - Iteration 103000 - Loss 46.93090057373047\n",
      "Training - Iteration 104000 - Loss 45.33669662475586\n",
      "Training - Iteration 105000 - Loss 44.75638961791992\n",
      "Training - Iteration 106000 - Loss 44.57279968261719\n",
      "Training - Iteration 107000 - Loss 45.302284240722656\n",
      "Training - Iteration 108000 - Loss 44.558441162109375\n",
      "Training - Iteration 109000 - Loss 44.411991119384766\n",
      "Training - Iteration 110000 - Loss 43.843223571777344\n",
      "\n",
      "murfonersed at the cthe walked eyon, Hermever thint eend lond a leulongickselalp. ke noo the drownkkars said, reen hisher atione griat, put the itho Horntar spiling this rite of the now  wHake be\n",
      "back\n",
      "\n",
      "Training - Iteration 111000 - Loss 44.97072219848633\n",
      "Training - Iteration 112000 - Loss 44.93978500366211\n",
      "Training - Iteration 113000 - Loss 45.21763229370117\n",
      "Training - Iteration 114000 - Loss 45.21399688720703\n",
      "Training - Iteration 115000 - Loss 45.460296630859375\n",
      "Training - Iteration 116000 - Loss 44.61772537231445\n",
      "Training - Iteration 117000 - Loss 45.30093765258789\n",
      "Training - Iteration 118000 - Loss 44.996517181396484\n",
      "Training - Iteration 119000 - Loss 43.7511100769043\n",
      "Training - Iteration 120000 - Loss 44.52125549316406\n",
      "\n",
      "on tobon tree ttocy too unen parde your proming showerly to the megted the stirholde, them to frop. restle the vinking eisting in a scrmered surm, of canded the his han tr kand, and Hherdan eationt gg\n",
      "\n",
      "Training - Iteration 121000 - Loss 44.01792907714844\n",
      "Training - Iteration 122000 - Loss 44.775962829589844\n",
      "Training - Iteration 123000 - Loss 42.969146728515625\n",
      "Training - Iteration 124000 - Loss 42.70844650268555\n",
      "Training - Iteration 125000 - Loss 43.18216323852539\n",
      "Training - Iteration 126000 - Loss 44.017024993896484\n",
      "Training - Iteration 127000 - Loss 43.708431243896484\n",
      "Training - Iteration 128000 - Loss 44.21845245361328\n",
      "Training - Iteration 129000 - Loss 42.881778717041016\n",
      "Training - Iteration 130000 - Loss 43.105430603027344\n",
      "\n",
      " the makin'tp in lissed my futher fely rinotving proave in cocked my faight.   and Harry for the sato  ke from lpa houser . . . hook   there werins upare doubred hec now... a con the hate. . .\"\n",
      "you de\n",
      "\n",
      "Training - Iteration 131000 - Loss 42.157649993896484\n",
      "Training - Iteration 132000 - Loss 42.8704833984375\n",
      "Training - Iteration 133000 - Loss 44.69927215576172\n",
      "Training - Iteration 134000 - Loss 44.637943267822266\n",
      "Training - Iteration 135000 - Loss 45.38795471191406\n",
      "Training - Iteration 136000 - Loss 45.10936737060547\n",
      "Training - Iteration 137000 - Loss 45.13410568237305\n",
      "Training - Iteration 138000 - Loss 45.21235275268555\n",
      "Training - Iteration 139000 - Loss 45.93975067138672\n",
      "Training - Iteration 140000 - Loss 47.496681213378906\n",
      "\n",
      "la is, clam masde saite b\" show poom, at droomy gearss got into had slape anle  casled dercitilutely unnery aff they Turn amep on out of crothers and thiugld refureame.hen lisife oy magman ,lut even t\n",
      "\n",
      "Training - Iteration 141000 - Loss 44.855918884277344\n",
      "Training - Iteration 142000 - Loss 44.45561981201172\n",
      "Training - Iteration 143000 - Loss 44.929405212402344\n",
      "Training - Iteration 144000 - Loss 47.211036682128906\n",
      "Training - Iteration 145000 - Loss 46.636436462402344\n",
      "Training - Iteration 146000 - Loss 45.221797943115234\n",
      "Training - Iteration 147000 - Loss 46.65117263793945\n",
      "Training - Iteration 148000 - Loss 45.536991119384766\n",
      "Training - Iteration 149000 - Loss 43.990142822265625\n",
      "Training - Iteration 150000 - Loss 44.13261032104492\n",
      "\n",
      "hinder when have hands cast tnsidests's go don't him like him, and he coo haw foron, vistaille, the artHarry's inting un aront im any-unon bett couldn't Harry htring him, hood said reat the dow. .\n",
      ". .\n",
      "\n",
      "Training - Iteration 151000 - Loss 44.740692138671875\n",
      "Training - Iteration 152000 - Loss 44.55260467529297\n",
      "Training - Iteration 153000 - Loss 43.54993438720703\n",
      "Training - Iteration 154000 - Loss 43.25614929199219\n",
      "Training - Iteration 155000 - Loss 43.996192932128906\n",
      "Training - Iteration 156000 - Loss 44.01803970336914\n",
      "Training - Iteration 157000 - Loss 44.319061279296875\n",
      "Training - Iteration 158000 - Loss 44.55750274658203\n",
      "Training - Iteration 159000 - Loss 44.689720153808594\n",
      "Training - Iteration 160000 - Loss 44.38539123535156\n",
      "\n",
      "was all pestering it you deet agoldoh,n before to a don't the creptran and ddinnite up nockari, to dow, very asked showing armsednobst the lewas pust no  any sause weers, inside rass and sear not, the\n",
      "\n",
      "Training - Iteration 161000 - Loss 44.4330940246582\n",
      "Training - Iteration 162000 - Loss 44.04633712768555\n",
      "Training - Iteration 163000 - Loss 43.78012466430664\n",
      "Training - Iteration 164000 - Loss 44.572898864746094\n",
      "Training - Iteration 165000 - Loss 43.69498825073242\n",
      "Training - Iteration 166000 - Loss 44.22800064086914\n",
      "Training - Iteration 167000 - Loss 43.24722671508789\n",
      "Training - Iteration 168000 - Loss 43.12770462036133\n",
      "Training - Iteration 169000 - Loss 43.064605712890625\n",
      "Training - Iteration 170000 - Loss 43.94269943237305\n",
      "\n",
      "w,\" he stoneble.\n",
      "\"gan \"le once, ythim whath of spery champly himblher he had sound in the chanday seetter coulds,\" said look. \n",
      "\"hu tlotter, dragble.  S\" ontterses him.  hese have botscated his day. . \n",
      "\n",
      "Training - Iteration 171000 - Loss 43.58230972290039\n",
      "Training - Iteration 172000 - Loss 43.390724182128906\n",
      "Training - Iteration 173000 - Loss 42.811134338378906\n",
      "Training - Iteration 174000 - Loss 42.38396453857422\n",
      "Training - Iteration 175000 - Loss 41.61589813232422\n",
      "Training - Iteration 176000 - Loss 42.315494537353516\n",
      "Training - Iteration 177000 - Loss 42.99856948852539\n",
      "Training - Iteration 178000 - Loss 45.018524169921875\n",
      "Training - Iteration 179000 - Loss 45.080535888671875\n",
      "Training - Iteration 180000 - Loss 45.01259231567383\n",
      "\n",
      "and eid eaced to went tonneadorer out oif Dudley,  saughter whenower his fach.\"\n",
      "ireps.  Harry law ewh ken the retter.\n",
      "\"Thirged in, what he unce, rudge to tharpeck, and upoalnged it was a retter go, va\n",
      "\n",
      "Training - Iteration 181000 - Loss 44.89437484741211\n",
      "Training - Iteration 182000 - Loss 44.75014877319336\n",
      "Training - Iteration 183000 - Loss 45.8880729675293\n",
      "Training - Iteration 184000 - Loss 47.21328353881836\n",
      "Training - Iteration 185000 - Loss 44.95911407470703\n",
      "Training - Iteration 186000 - Loss 44.07878875732422\n",
      "Training - Iteration 187000 - Loss 44.323795318603516\n",
      "Training - Iteration 188000 - Loss 47.9216194152832\n",
      "Training - Iteration 189000 - Loss 47.014190673828125\n",
      "Training - Iteration 190000 - Loss 45.667266845703125\n",
      "\n",
      ". foing over and now of herself eharmation were remely bedild stayed piaten rooclabus teaidby thes. wo weant dowiver behin, and paited witchem's itsild every spangblown sidebvead ball pporned balpectl\n",
      "\n",
      "Training - Iteration 191000 - Loss 44.42215347290039\n",
      "Training - Iteration 192000 - Loss 45.5057373046875\n",
      "Training - Iteration 193000 - Loss 44.06060028076172\n",
      "Training - Iteration 194000 - Loss 44.068851470947266\n",
      "Training - Iteration 195000 - Loss 43.677913665771484\n",
      "Training - Iteration 196000 - Loss 44.510826110839844\n",
      "Training - Iteration 197000 - Loss 43.64609146118164\n",
      "Training - Iteration 198000 - Loss 43.19356155395508\n",
      "Training - Iteration 199000 - Loss 42.9374885559082\n",
      "Training - Iteration 200000 - Loss 44.0892333984375\n",
      "\n",
      " waricuging than, which woings.  on.  bothing working, wirk parns. aTd lown reating to peovever, and now for bristnead Dhouncrewling  Iy arwiring upbin.\n",
      "\n",
      "in his handvaked to mo thany sco dather\n",
      "fuck a\n",
      "\n",
      "Training - Iteration 201000 - Loss 44.41910934448242\n",
      "Training - Iteration 202000 - Loss 44.415687561035156\n",
      "Training - Iteration 203000 - Loss 44.57786178588867\n",
      "Training - Iteration 204000 - Loss 44.160282135009766\n",
      "Training - Iteration 205000 - Loss 44.3315315246582\n",
      "Training - Iteration 206000 - Loss 43.54346466064453\n",
      "Training - Iteration 207000 - Loss 43.804080963134766\n",
      "Training - Iteration 208000 - Loss 43.8476448059082\n",
      "Training - Iteration 209000 - Loss 43.58865737915039\n",
      "Training - Iteration 210000 - Loss 43.951080322265625\n",
      "\n",
      "hasser of the , his lidt them with airind.  \"sHermione, if inruse hanaten, loored it.  Hanking an elt only the les is he with the crearime himso then ., he walking looking Secure enowymle off liatlves\n",
      "\n",
      "Training - Iteration 211000 - Loss 43.03059387207031\n",
      "Training - Iteration 212000 - Loss 42.42136001586914\n",
      "Training - Iteration 213000 - Loss 42.894569396972656\n",
      "Training - Iteration 214000 - Loss 42.348392486572266\n",
      "Training - Iteration 215000 - Loss 43.00144577026367\n",
      "Training - Iteration 216000 - Loss 42.3867073059082\n",
      "Training - Iteration 217000 - Loss 43.30703353881836\n",
      "Training - Iteration 218000 - Loss 42.13972473144531\n",
      "Training - Iteration 219000 - Loss 41.84991455078125\n",
      "Training - Iteration 220000 - Loss 42.32744598388672\n",
      "\n",
      "e the liders has anbinen, its and atiwing hiring for a heppeasld persion who has reslensx ever know sittering up.  only to stepped over the acredorm, shappented, to all strieds -. yoveated his for wha\n",
      "\n",
      "Training - Iteration 221000 - Loss 42.540740966796875\n",
      "Training - Iteration 222000 - Loss 44.6549072265625\n",
      "Training - Iteration 223000 - Loss 43.776458740234375\n",
      "Training - Iteration 224000 - Loss 44.78240203857422\n",
      "Training - Iteration 225000 - Loss 44.384124755859375\n",
      "Training - Iteration 226000 - Loss 44.72465133666992\n",
      "Training - Iteration 227000 - Loss 45.523902893066406\n",
      "Training - Iteration 228000 - Loss 46.73102951049805\n",
      "Training - Iteration 229000 - Loss 45.34404754638672\n",
      "Training - Iteration 230000 - Loss 43.01158142089844\n",
      "\n",
      "ren, what was bet targe seemed itlate her were senkid nots windy, pottly.\n",
      "\"ion them behard. \"adient, peanturing gisted wizarden.\n",
      "\", yed to like it, thuconding anper a beanging with edoay, \"back, mumor\n",
      "\n",
      "Training - Iteration 231000 - Loss 44.093971252441406\n",
      "Training - Iteration 232000 - Loss 44.82658767700195\n",
      "Training - Iteration 233000 - Loss 45.802040100097656\n",
      "Training - Iteration 234000 - Loss 45.98835754394531\n",
      "Training - Iteration 235000 - Loss 44.26344680786133\n",
      "Training - Iteration 236000 - Loss 45.55886459350586\n",
      "Training - Iteration 237000 - Loss 43.7172737121582\n",
      "Training - Iteration 238000 - Loss 43.70038604736328\n",
      "Training - Iteration 239000 - Loss 43.33902359008789\n",
      "Training - Iteration 240000 - Loss 44.152835845947266\n",
      "\n",
      "must into the renten in a champions.\n",
      "\"on, whires, when he cold grear, and.  your potting back ontour the rupsimbingers osrep at a namentoryt she scpirenticalle, \"n lesk oice.  \"\n",
      "\"rauser and scranverin\n",
      "\n",
      "Training - Iteration 241000 - Loss 43.15583801269531\n",
      "Training - Iteration 242000 - Loss 43.066444396972656\n",
      "Training - Iteration 243000 - Loss 42.64090347290039\n",
      "Training - Iteration 244000 - Loss 44.13148498535156\n",
      "Training - Iteration 245000 - Loss 43.834815979003906\n",
      "Training - Iteration 246000 - Loss 44.1294059753418\n",
      "Training - Iteration 247000 - Loss 44.23447036743164\n",
      "Training - Iteration 248000 - Loss 44.86729049682617\n",
      "Training - Iteration 249000 - Loss 43.860008239746094\n",
      "Training - Iteration 250000 - Loss 44.0788688659668\n",
      "\n",
      "ed me at the offilibled on nis rirTher heare had move at his a nearing into tome fails betone of sturned, slowlon maHcorffince, and pulled boul and said his head,latc's your ush fathers.\n",
      "\"ft fhe moudo\n",
      "\n",
      "Training - Iteration 251000 - Loss 44.00352096557617\n",
      "Training - Iteration 252000 - Loss 42.9447021484375\n",
      "Training - Iteration 253000 - Loss 43.603782653808594\n",
      "Training - Iteration 254000 - Loss 42.9923095703125\n",
      "Training - Iteration 255000 - Loss 43.663143157958984\n",
      "Training - Iteration 256000 - Loss 41.961143493652344\n",
      "Training - Iteration 257000 - Loss 41.92375946044922\n",
      "Training - Iteration 258000 - Loss 41.837833404541016\n",
      "Training - Iteration 259000 - Loss 43.06221389770508\n",
      "Training - Iteration 260000 - Loss 42.628692626953125\n",
      "\n",
      "ched.  Harrys pus the head,latdinged oiding in mean, ungent becore as the hand, he groundrit\"\n",
      "Horing to the Tups .. I\n",
      "grefionstout hid\"r that ond sunound the tarie ptall - gelled and and sparing falbl\n",
      "\n",
      "Training - Iteration 261000 - Loss 43.332645416259766\n",
      "Training - Iteration 262000 - Loss 41.84416961669922\n",
      "Training - Iteration 263000 - Loss 41.96958541870117\n",
      "Training - Iteration 264000 - Loss 41.56186294555664\n",
      "Training - Iteration 265000 - Loss 41.943721771240234\n",
      "Training - Iteration 266000 - Loss 44.37302017211914\n",
      "Training - Iteration 267000 - Loss 43.80507278442383\n",
      "Training - Iteration 268000 - Loss 44.536685943603516\n",
      "Training - Iteration 269000 - Loss 44.16472244262695\n",
      "Training - Iteration 270000 - Loss 44.30490493774414\n",
      "\n",
      "ptrswing he side, away away floater, revering the trough nop reenous eagurt ty a longet to into the wand we\"ke not have  orcodn't remaddly at their Malantly athkead a had bla one hoited to an to thet \n",
      "\n",
      "Training - Iteration 271000 - Loss 44.75154113769531\n",
      "Training - Iteration 272000 - Loss 45.438724517822266\n",
      "Training - Iteration 273000 - Loss 46.295921325683594\n",
      "Training - Iteration 274000 - Loss 43.76355743408203\n",
      "Training - Iteration 275000 - Loss 43.83258056640625\n",
      "Training - Iteration 276000 - Loss 44.153987884521484\n",
      "Training - Iteration 277000 - Loss 46.14604187011719\n",
      "Training - Iteration 278000 - Loss 46.15269470214844\n",
      "Training - Iteration 279000 - Loss 44.2119026184082\n",
      "Training - Iteration 280000 - Loss 45.64215850830078\n",
      "\n",
      "argoian from this not even their finned decthing.\n",
      "\", his eyath meth ank cles.\n",
      "It walked undored a could reift tokiodd to ass.  Hi wervarory goftigal hy delenst, ?\"\n",
      " He hages, to fincelt was speecliwn \n",
      "\n",
      "Training - Iteration 281000 - Loss 44.31122589111328\n",
      "Training - Iteration 282000 - Loss 43.07023620605469\n",
      "Training - Iteration 283000 - Loss 43.047019958496094\n",
      "Training - Iteration 284000 - Loss 43.98743438720703\n",
      "Training - Iteration 285000 - Loss 43.60911178588867\n",
      "Training - Iteration 286000 - Loss 42.63628005981445\n",
      "Training - Iteration 287000 - Loss 42.43978500366211\n",
      "Training - Iteration 288000 - Loss 43.353546142578125\n",
      "Training - Iteration 289000 - Loss 43.78767776489258\n",
      "Training - Iteration 290000 - Loss 43.68097686767578\n",
      "\n",
      "flat hass thom, and had a, said enge itching.  you're hasthmen rower.  Wly sat it,\" said moom to ciring to seemed,\"\n",
      "and their misiown dosa, and mes,-\" est slessed arrivs were , \"now, yoy beut a well. \n",
      "\n",
      "Training - Iteration 291000 - Loss 44.28840637207031\n",
      "Training - Iteration 292000 - Loss 43.63286590576172\n",
      "Training - Iteration 293000 - Loss 43.77355194091797\n",
      "Training - Iteration 294000 - Loss 43.730201721191406\n",
      "Training - Iteration 295000 - Loss 43.42294692993164\n",
      "Training - Iteration 296000 - Loss 42.97032165527344\n",
      "Training - Iteration 297000 - Loss 43.87620162963867\n",
      "Training - Iteration 298000 - Loss 42.846527099609375\n",
      "Training - Iteration 299000 - Loss 43.60422897338867\n",
      "Training - Iteration 300000 - Loss 42.43684387207031\n",
      "\n",
      "o est inside worlHe appring down voram,\" Heen it.\n",
      "one yes rementernairs were gof forw into the daxing, at ercording a houd,\" snapped.\n",
      "\"Harry sapwed you up,\" he said. . ...\n",
      "worrs of his take in you in \n",
      "\n",
      "Training - Iteration 301000 - Loss 42.329368591308594\n",
      "Training - Iteration 302000 - Loss 42.30663299560547\n",
      "Training - Iteration 303000 - Loss 43.18452835083008\n",
      "Training - Iteration 304000 - Loss 42.76901626586914\n",
      "Training - Iteration 305000 - Loss 43.09429168701172\n",
      "Training - Iteration 306000 - Loss 41.944725036621094\n",
      "Training - Iteration 307000 - Loss 41.80488586425781\n",
      "Training - Iteration 308000 - Loss 40.80608367919922\n",
      "Training - Iteration 309000 - Loss 41.66738510131836\n",
      "Training - Iteration 310000 - Loss 42.61802673339844\n",
      "\n",
      "yes more thoughtraced real. yoo with aisn't in them looked to is.\"\n",
      "\"The had week bloatery, he win up the face anded dound to rop gorning even, she vilsmented into knew sloun sotter.\n",
      "\"e tyould veet un \n",
      "\n",
      "Training - Iteration 311000 - Loss 44.17090606689453\n",
      "Training - Iteration 312000 - Loss 44.61129379272461\n",
      "Training - Iteration 313000 - Loss 44.04811096191406\n",
      "Training - Iteration 314000 - Loss 44.120792388916016\n",
      "Training - Iteration 315000 - Loss 44.307403564453125\n",
      "Training - Iteration 316000 - Loss 45.141414642333984\n",
      "Training - Iteration 317000 - Loss 46.92599868774414\n",
      "Training - Iteration 318000 - Loss 43.96281433105469\n",
      "Training - Iteration 319000 - Loss 43.50333023071289\n",
      "Training - Iteration 320000 - Loss 43.274356842041016\n",
      "\n",
      "ished Harryg other, you're now a learly, ehindingaying alling.   what aty for it onle wat to dusioking down inersay worle forhering to be stay went to mean.\n",
      ".k y-u comminger taklam, shouted the trick \n",
      "\n",
      "Training - Iteration 321000 - Loss 46.8695068359375\n",
      "Training - Iteration 322000 - Loss 45.95877456665039\n",
      "Training - Iteration 323000 - Loss 44.692901611328125\n",
      "Training - Iteration 324000 - Loss 43.813987731933594\n",
      "Training - Iteration 325000 - Loss 45.0734748840332\n",
      "Training - Iteration 326000 - Loss 43.42068862915039\n",
      "Training - Iteration 327000 - Loss 43.2118034362793\n",
      "Training - Iteration 328000 - Loss 43.4791374206543\n",
      "Training - Iteration 329000 - Loss 43.9002571105957\n",
      "Training - Iteration 330000 - Loss 42.80087661743164\n",
      "\n",
      "into teld him now.  He wrevents to when drainly snated was bearouy said and were, dengeing to the crubion of the fire up ole told bever to aw  saw him, it had no where didn'tching atten hoed.\n",
      "balk the\n",
      "\n",
      "Training - Iteration 331000 - Loss 42.49142837524414\n",
      "Training - Iteration 332000 - Loss 42.85009765625\n",
      "Training - Iteration 333000 - Loss 43.49251937866211\n",
      "Training - Iteration 334000 - Loss 43.975341796875\n",
      "Training - Iteration 335000 - Loss 43.81886672973633\n",
      "Training - Iteration 336000 - Loss 43.9056396484375\n",
      "Training - Iteration 337000 - Loss 43.46966552734375\n",
      "Training - Iteration 338000 - Loss 43.787620544433594\n",
      "Training - Iteration 339000 - Loss 43.12465286254883\n",
      "Training - Iteration 340000 - Loss 43.1186408996582\n",
      "\n",
      "apist whfop, is dark, shat hown com, had ne unilory, water long was help?  hirted e grop,\", thing the trigg that his wannly of his his fadmaroul and stock putt.  'er belned a spirele. . . botherrantin\n",
      "\n",
      "Training - Iteration 341000 - Loss 43.81890869140625\n",
      "Training - Iteration 342000 - Loss 43.0835075378418\n",
      "Training - Iteration 343000 - Loss 43.52606201171875\n",
      "Training - Iteration 344000 - Loss 42.54000473022461\n",
      "Training - Iteration 345000 - Loss 41.780643463134766\n",
      "Training - Iteration 346000 - Loss 42.200897216796875\n",
      "Training - Iteration 347000 - Loss 42.58879470825195\n",
      "Training - Iteration 348000 - Loss 42.37262725830078\n",
      "Training - Iteration 349000 - Loss 42.07567596435547\n",
      "Training - Iteration 350000 - Loss 42.62959671020508\n",
      "\n",
      " ston, him in the poster.  \n",
      "shan of rover cold, in my didself go instersaid, I want toos ba you widdin, lobd ... botstreps, and the his haired the Dryated, looking as tho was blarly.  other to be bott\n",
      "\n",
      "Training - Iteration 351000 - Loss 41.81377410888672\n",
      "Training - Iteration 352000 - Loss 41.28489303588867\n",
      "Training - Iteration 353000 - Loss 41.79745864868164\n",
      "Training - Iteration 354000 - Loss 41.92855453491211\n",
      "Training - Iteration 355000 - Loss 44.52123260498047\n",
      "Training - Iteration 356000 - Loss 43.67814254760742\n",
      "Training - Iteration 357000 - Loss 44.586063385009766\n",
      "Training - Iteration 358000 - Loss 43.83613204956055\n",
      "Training - Iteration 359000 - Loss 44.01176834106445\n",
      "Training - Iteration 360000 - Loss 45.11494827270508\n",
      "\n",
      "et a perrected hriling findiaming gcretchic etirtiagd reached se.  \"casher ole, they hulrer, and sitea troncered Mr. \"onelated front, onting of to by fintorn tima phear, and see slour.\n",
      " dlaler buthed,\n",
      "\n",
      "Training - Iteration 361000 - Loss 46.79060745239258\n",
      "Training - Iteration 362000 - Loss 44.74936294555664\n",
      "Training - Iteration 363000 - Loss 42.44984817504883\n",
      "Training - Iteration 364000 - Loss 43.39159393310547\n",
      "Training - Iteration 365000 - Loss 45.24089813232422\n",
      "Training - Iteration 366000 - Loss 45.58161163330078\n",
      "Training - Iteration 367000 - Loss 45.43325424194336\n",
      "Training - Iteration 368000 - Loss 43.80528259277344\n",
      "Training - Iteration 369000 - Loss 44.96321487426758\n",
      "Training - Iteration 370000 - Loss 43.19251251220703\n",
      "\n",
      "ton thevery aguringly of risa and where in uddinl, his armione himseade.  rement eiving.  He standildn't the dreamss to theylat, and mind a thoughts intreasor and stuct tow siled to the shook lobble b\n",
      "\n",
      "Training - Iteration 371000 - Loss 42.91852951049805\n",
      "Training - Iteration 372000 - Loss 42.89066696166992\n",
      "Training - Iteration 373000 - Loss 43.75901794433594\n",
      "Training - Iteration 374000 - Loss 42.73843002319336\n",
      "Training - Iteration 375000 - Loss 42.610469818115234\n",
      "Training - Iteration 376000 - Loss 42.336883544921875\n",
      "Training - Iteration 377000 - Loss 43.532867431640625\n",
      "Training - Iteration 378000 - Loss 43.503108978271484\n",
      "Training - Iteration 379000 - Loss 43.69888687133789\n",
      "Training - Iteration 380000 - Loss 43.82892608642578\n",
      "\n",
      "her goed to plock and ne ban had sisterdodd causting a. nud of the tirine about, stes. han theise the pan.t' get stell them.\n",
      "\"res , and he was as their-seen, it a way near, whf cuptyell it sitting on \n",
      "\n",
      "Training - Iteration 381000 - Loss 43.899715423583984\n",
      "Training - Iteration 382000 - Loss 43.57154083251953\n",
      "Training - Iteration 383000 - Loss 43.24536895751953\n",
      "Training - Iteration 384000 - Loss 43.459983825683594\n",
      "Training - Iteration 385000 - Loss 42.734127044677734\n",
      "Training - Iteration 386000 - Loss 43.36107635498047\n",
      "Training - Iteration 387000 - Loss 42.436763763427734\n",
      "Training - Iteration 388000 - Loss 42.939334869384766\n",
      "Training - Iteration 389000 - Loss 41.50438690185547\n",
      "Training - Iteration 390000 - Loss 41.91812515258789\n",
      "\n",
      "might him ingionedeled bowness.\n",
      "\"'te frenfig, with he was to, thisk, back insidely calucefor . . . peanscios,. \n",
      "\"futticr seople sighert intory. . . .vembless in them and sioked was Harry, of seeploy T\n",
      "\n",
      "Training - Iteration 391000 - Loss 41.535797119140625\n",
      "Training - Iteration 392000 - Loss 42.286006927490234\n",
      "Training - Iteration 393000 - Loss 41.776493072509766\n",
      "Training - Iteration 394000 - Loss 43.019412994384766\n",
      "Training - Iteration 395000 - Loss 41.64413070678711\n",
      "Training - Iteration 396000 - Loss 41.51728820800781\n",
      "Training - Iteration 397000 - Loss 41.27222442626953\n",
      "Training - Iteration 398000 - Loss 41.39558792114258\n",
      "Training - Iteration 399000 - Loss 43.90929412841797\n",
      "Training - Iteration 400000 - Loss 43.273929595947266\n",
      "\n",
      "ng of the light back down on his for it stepl with the endeated him atto wnon its acred not to mentthing his edo it with his started then he looked from moriid spoke him, thint cold one had soon the w\n",
      "\n",
      "Training - Iteration 401000 - Loss 44.098262786865234\n",
      "Training - Iteration 402000 - Loss 43.77490234375\n",
      "Training - Iteration 403000 - Loss 43.83452224731445\n",
      "Training - Iteration 404000 - Loss 44.568485260009766\n",
      "Training - Iteration 405000 - Loss 44.83432388305664\n",
      "Training - Iteration 406000 - Loss 45.274906158447266\n",
      "Training - Iteration 407000 - Loss 43.120845794677734\n",
      "Training - Iteration 408000 - Loss 43.20281982421875\n",
      "Training - Iteration 409000 - Loss 43.984397888183594\n",
      "Training - Iteration 410000 - Loss 45.3786735534668\n",
      "\n",
      "aises capenes told for schoobled the \n",
      "hoos of to ture much and Te,\" he said thinking the off hoice ne the wrose were years, some evertatichy coment, ano i as he prebe coured the to hours, looking wist\n",
      "\n",
      "Training - Iteration 411000 - Loss 45.56507873535156\n",
      "Training - Iteration 412000 - Loss 43.730350494384766\n",
      "Training - Iteration 413000 - Loss 45.319129943847656\n",
      "Training - Iteration 414000 - Loss 43.710750579833984\n",
      "Training - Iteration 415000 - Loss 42.78376770019531\n",
      "Training - Iteration 416000 - Loss 42.638427734375\n",
      "Training - Iteration 417000 - Loss 43.607635498046875\n",
      "Training - Iteration 418000 - Loss 42.96257400512695\n",
      "Training - Iteration 419000 - Loss 42.542423248291016\n",
      "Training - Iteration 420000 - Loss 42.131378173828125\n",
      "\n",
      "ff\n",
      "- this side on the bouldn's iden real underswate the carm.\n",
      "\"uidert wnous now tingy I'man off turns, and nights sulencle, the riwards.\n",
      "\"yeann a note back, which though over look.  dony think you eve\n",
      "\n",
      "Training - Iteration 421000 - Loss 43.21427536010742\n",
      "Training - Iteration 422000 - Loss 43.35771179199219\n",
      "Training - Iteration 423000 - Loss 43.428810119628906\n",
      "Training - Iteration 424000 - Loss 43.70329666137695\n",
      "Training - Iteration 425000 - Loss 43.080055236816406\n",
      "Training - Iteration 426000 - Loss 42.92942428588867\n",
      "Training - Iteration 427000 - Loss 43.552799224853516\n",
      "Training - Iteration 428000 - Loss 42.91356658935547\n",
      "Training - Iteration 429000 - Loss 42.345680236816406\n",
      "Training - Iteration 430000 - Loss 43.35574722290039\n",
      "\n",
      "he imasting anything hirs.  caterottered Hermione somety, no more making his mistle ptisebyes a dras. . . swat scares snifted to fell was not from appedbind whist a pate waited as them inte no.  in cl\n",
      "\n",
      "Training - Iteration 431000 - Loss 42.552085876464844\n",
      "Training - Iteration 432000 - Loss 43.15961837768555\n",
      "Training - Iteration 433000 - Loss 41.76326370239258\n",
      "Training - Iteration 434000 - Loss 41.64288330078125\n",
      "Training - Iteration 435000 - Loss 41.73457717895508\n",
      "Training - Iteration 436000 - Loss 42.54988479614258\n",
      "Training - Iteration 437000 - Loss 42.135597229003906\n",
      "Training - Iteration 438000 - Loss 42.83889389038086\n",
      "Training - Iteration 439000 - Loss 41.359039306640625\n",
      "Training - Iteration 440000 - Loss 41.75676727294922\n",
      "\n",
      "ck, pointared acmotter and itking though concider out of I seepice was cling have looked the wooder, so saished kefcestoly.  worting uping on unwarry. \n",
      "llens stwill sctlishorled ols be gorused.\n",
      "\"Ho, w\n",
      "\n",
      "Training - Iteration 441000 - Loss 40.54471969604492\n",
      "Training - Iteration 442000 - Loss 41.13680648803711\n",
      "Training - Iteration 443000 - Loss 42.33556365966797\n",
      "Training done - Best loss: 40.45977020263672\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "rnn.train(book_data, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haent the edgeent off \n",
      "mi meut on to kill.\"\n",
      "ro that wahal of thest it that him was gold now, and Harry told to she his newst and Harry, under reace fathering there, Harry,\" Harry detting this edgening yourt Dumbledgrtaira, the drommaneways were streach we a menticirway,\" said use twarep his read, and he was and trie, hand, bess ascold here want one of the faning eye.  hinding corgact disgurned still got ittannoy for its let to we tonam knew them into the now and had virius you,\"\" his mot might at that staiting and almogious for not off, as happened to drame brealoudely , he s cent let.  irvis on dim sens will invescoing to him, shorred, and piaved,\" said Dumbledore bemorect, and it oncreturt of roldoning.   his wand like it was at anst had misting eyes well over knownish's well wath as he reoum to none said aching enside on the profestle down though what \n",
      "le to himself, and thofting Dark you aite sbrewing as e,  the pleas . . . . he shout.  He one office, his mouto ianet was eyes towild\n"
     ]
    }
   ],
   "source": [
    "starting_char = 'H'\n",
    "X = torch.zeros((K, 1)).to(device)\n",
    "X[char2ind[starting_char], 0] = 1\n",
    "h = torch.zeros((rnn.m, 1)).to(device)\n",
    "Y = rnn.synthesize(h, X, 1000, best=True)\n",
    "print(starting_char + ''.join([ind2char[torch.argmax(Y[:, i]).item()] for i in range(1000)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
